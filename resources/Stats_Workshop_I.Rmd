---
title: 'Stats workshop-I'
output:
github_document:
toc: yes
toc_float: yes
---

# Quick stats workshop

Load libraries and set theme for figures

```{r}
library(tidyverse)
theme_set(theme_bw())
library(rmarkdown)
render_this <- function(){rmarkdown::render('/Users/zeynepenkavi/Dropbox/PoldrackLab/training_resources/resources/Stats_Workshop_I.Rmd', output_dir = '/Users/zeynepenkavi/Dropbox/PoldrackLab/training_resources/resources', html_notebook(toc = T, toc_float = T, toc_depth = 2, code_folding = 'hide'))}
```

This is a quick workshop covering some frequently used statistical tests in psych. The goal is not to cover all the theory and math underlying these tests but to provide an intuition on what question they are intended to address, what their main inputs and outputs are, how they are often visualized and how to run them in R.

To demonstrate most of the methods we'll use a sample dataset provided in R.

```{r}
iris
```

### Always start with getting a sense of your data!!

```{r}
str(iris)
```

```{r}
summary(iris)
```

## (Linear) Correlation - Pearson's correlation

- Number of variables: 2  
- Type of variables: continous  
- Output: r value, p value  
- Typical plot: scatter plot  

```{r}
cor(iris$Sepal.Length, iris$Sepal.Width)
```

```{r}
cor.test(iris$Sepal.Length, iris$Sepal.Width)
```

```{r}
iris %>%
  ggplot(aes(Sepal.Length, Sepal.Width))+
  geom_point()+
  geom_smooth(method="lm")
```

```{r}
cor.test(iris$Petal.Length, iris$Petal.Width)
```

```{r}
iris %>%
  ggplot(aes(Petal.Length, Petal.Width))+
  geom_point()+
  geom_smooth(method="lm")
```

## T-test

- Number of variables: 2  
- Type of variables: 1 continous, 1 categorical with 2 levels  
- Output: t value, df, p value  
- Typical plot: boxplot, barplot  

Important arguments for the `t.test` function:
- `alternative`: depends on what hypothesis you are testing (are the distributions different vs. is the mean of one `greater` or `less` than the other)
- `paired`: default is `FALSE`; should be set to `TRUE` if the levels refer to different conditions for the same sample

```{r}
iris %>%
  filter(Species != "virginica") %>%
  ggplot(aes(Species, Sepal.Length))+
  geom_boxplot()
```

```{r}
iris %>%
  filter(Species != "virginica") %>%
  ggplot(aes(Sepal.Length, fill=Species, col=Species))+
  geom_density(alpha=0.5)
```

```{r}
data = iris %>%
  filter(Species != "virginica")
t.test(Sepal.Length ~ Species, data)
```

```{r}
t.test(Sepal.Length ~ Species, data, alternative = "less")
```

```{r}
t.test(Sepal.Length ~ Species, data, alternative = "less")$p.value < t.test(Sepal.Length ~ Species, data)$p.value
```

```{r}
t.test(Sepal.Length ~ Species, data, alternative = "greater")
```

## ANOVA

- Number of variables: >=2  
- Type of variables: 1 continous DV, >=1 IV both continuos and categorical   
- Output: F value, df, p value  
- Typical plot: boxplot, barplot  

```{r}
iris %>%
  ggplot(aes(Species, Sepal.Length))+
  geom_boxplot()
```

```{r}
iris %>%
  ggplot(aes(Sepal.Length, fill=Species, col=Species))+
  geom_density(alpha=0.5)
```

```{r}
iris %>% 
  group_by(Species) %>%
  summarise(mean_sl = mean(Sepal.Length),
            sem_sl = sd(Sepal.Length)/sqrt(n())) %>%
  ggplot(aes(Species, mean_sl, fill=Species))+
  geom_bar(stat = 'identity', alpha = 0.5, width = 0.75)+
  geom_errorbar(aes(ymin = mean_sl-sem_sl, ymax = mean_sl+sem_sl), width = 0.5)+
  xlab("Mean Sepal Length")
```

Only tells us that the means for the groups are different. DOES NOT tell us which is greater than the other. To determine that you'd either run pairwise t-tests or linear regression.

```{r}
summary(aov(Sepal.Length ~ Species, iris))
```

Pairwise t-test still DOES NOT tell us which distribution has a higher mean compared to the others. It tells us which two distributions are different than each other.

```{r}
with(iris, pairwise.t.test(Sepal.Length, Species))
```

## Linear regression

- Number of variables: >=2  
- Type of variables: 1 continous DV, >=1 IV both continuos and categorical    
- Output: (standardized) regression coefficients, t value, df, p value   
- Typical plot: scatterplot, boxplot, barplot  

```{r}
iris %>%
  ggplot(aes(Petal.Length, Petal.Width, color=Species))+
  geom_point()+
  geom_smooth(method = "lm")
```

```{r}
summary(lm(Petal.Width ~ Petal.Length+Species, iris))
```

This is an additive model. It checks for the main effect of `Species` and of `Petal.Length` separately. It tests whether   
1. `Petal.Width` increases significantly as `Petal.Length` increases
2. There are significant differences between the average `Petal.Width` of the other two `Species` compared to setosa.  

It DOES NOT check whether `Petal.Width` increases significantly by `Petal.Length` at *different rates* depending on the `Species`. This would be an *interactive* model.

### Model comparison/selection

CAN ONLY BE DONE WITH NESTED MODELS

```{r}
m1a = lm(Petal.Width ~ Petal.Length, iris)
m1b = lm(Petal.Width ~ Species, iris)
m2 = lm(Petal.Width ~ Petal.Length+Species, iris)
m3 = lm(Petal.Width ~ Petal.Length*Species, iris)
```

```{r}
anova(m1a, m2, m3)
```

```{r}
anova(m1b, m2, m3)
```

Conclusion: `m2`, the additive model, is the best.

## Generalized linear regression

- Number of variables: >=2  
- Type of variables: 1 DV of any type (e.g. binary responses), >=1 IV both continuos and categorical  
- Output: (standardized) regression coefficients, t value, df, p value  
- Typical plot: scatterplot, boxplot, barplot  

```{r}

```

## Repeated measures

Within versus between subject factors
Fixed versus random effects

## Conceptual questions

### What is a z-value

How many *population* standard deviations a raw value is away from the *population* mean.

```{r}
data = data.frame(x = rnorm(1000, mean=5, sd=1))
data = data %>%
  mutate(vals = dnorm(x, mean=5))

data %>%
  ggplot(aes(x, vals))+
  geom_line(group=1)
```

### What is a t-value

How many *sample* standard deviations a raw value is away from the *sample* mean.

```{r}
sample_data = sample_n(data, 20)

sample_data %>%
  ggplot()+
  geom_line(aes(x, vals), group=1, col='red')+
  geom_line(data=data, aes(x, vals), linetype='dashed')
```

```{r}
raw_value = sample_data$x[1]
cat("Sampled data point\n")
raw_value

cat("Mean of population\n")
mean(data$x)
cat("Standard deviation of population\n")
sd(data$x)

cat("z_score of sampled data point\n")
(raw_value - 5)/(1)

cat("Probability of sampling a value smaller than this number from this population\n")
pnorm((raw_value - 5)/(1))

cat("Mean of sample of 20\n")
mean(sample_data$x)
cat("Standard deviation of sample of 20\n")
sd(sample_data$x)

cat("t_score of sampled data point\n")
(raw_value - mean(sample_data$x)) / (sd(sample_data$x))

cat("Probability of sampling a value smaller than this number from this sample\n")
pt((raw_value - mean(sample_data$x)) / (sd(sample_data$x)), df = nrow(sample_data) -1)
```

### What is a p-value

Probability of observing your data given your null hypothesis. The smaller is it the more likely you are to 'reject' your null hypothesis. Note that this DOES NOT tell you   
- the probability that you alternative hypothesis is true or  
- the probability that your null hypothesis is false.  
To estimate probabilities of hypotheses depending on data you have observed you'd use Bayes' rule.

## TIPS:

- I repeat: Always start with getting a good understanding of the structure of your data.  
- Not fully comprehensive but [here](http://abacus.bates.edu/~ganderso/biology/resources/stats_flow_chart_v2014.pdf) is an example flowchart of how to choose the correct statistical test depending on your data.  
- Whenever you have a question on your data try to imagine what the plot should look like.  
- Better yet simulate some data (i.e. create some fake data) and actually make the plot.  